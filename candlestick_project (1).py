# -*- coding: utf-8 -*-
"""Candlestick project

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1WtvXr5UiKb8TzlAhmXjBNUu-mAtPEUWB
"""

import os
import zipfile
import pandas as pd
import numpy as np
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense, Dropout
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.utils import to_categorical
from sklearn.preprocessing import MinMaxScaler, LabelEncoder
from sklearn.model_selection import train_test_split
import matplotlib.pyplot as plt

import os
import zipfile

zip_file_path = "/content/candlestick_dataset_test.zip"  # Verify this path is correct
extract_path = "/content/candlestick_data_test"

# Check if the file exists
if not os.path.exists(zip_file_path):
    print(f"Error: File not found at '{zip_file_path}'")
else:
    # Check if the file is a valid zip file
    try:
        with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:
            # If it's a valid zip file, extract it
            zip_ref.extractall(extract_path)
            extracted_files = os.listdir(extract_path)
            print("Extracted Files:", extracted_files)
    except zipfile.BadZipFile:
        print(f"Error: '{zip_file_path}' is not a valid zip file.")

import os
import pandas as pd

# Path where ZIP was extracted
dataset_path = "/content/candlestick_dataa1"

# List all categories (candlestick pattern names)
categories = os.listdir(dataset_path)
print("Candlestick Patterns Found:", categories)

# Collect image file paths and labels
image_paths = []
labels = []

for category in categories:
    category_path = os.path.join(dataset_path, category)

    # Ensure it's a directory
    if os.path.isdir(category_path):
        for image in os.listdir(category_path):
            image_path = os.path.join(category_path, image)
            image_paths.append(image_path)
            labels.append(category)  # Label is the folder name

# Create a DataFrame for reference
df = pd.DataFrame({'image_path': image_paths, 'label': labels})
print(df.head())

import cv2
import numpy as np
from tqdm import tqdm

image_size = (128, 128)  # Resize images for uniformity

X = []  # Features (images)
y = []  # Labels (candlestick pattern names)

for i, img_path in enumerate(tqdm(df['image_path'])):
    img = cv2.imread(img_path)
    img = cv2.resize(img, image_size)  # Resize image
    img = img / 255.0  # Normalize pixel values
    X.append(img)
    y.append(df['label'][i])

X = np.array(X)
y = np.array(y)

print("Dataset shape:", X.shape, y.shape)

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder

# Convert labels to numbers
label_encoder = LabelEncoder()
y_encoded = label_encoder.fit_transform(y)

# Split dataset into train & test
X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)

print("Training set size:", X_train.shape)
print("Test set size:", X_test.shape)

!pip install tensorflow scikit-learn matplotlib opencv-python

import tensorflow as tf
from tensorflow import keras
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout
import matplotlib.pyplot as plt

# Define CNN Model
model = Sequential([
    Conv2D(32, (3, 3), activation='relu', input_shape=(128, 128, 3)),
    MaxPooling2D(2, 2),

    Conv2D(64, (3, 3), activation='relu'),
    MaxPooling2D(2, 2),

    Conv2D(128, (3, 3), activation='relu'),
    MaxPooling2D(2, 2),

    Flatten(),
    Dense(128, activation='relu'),
    Dropout(0.5),
    Dense(len(label_encoder.classes_), activation='softmax')  # Output layer
])

# Compile Model
model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])

# Train Model
history = model.fit(X_train, y_train, epochs=10, validation_data=(X_test, y_test), batch_size=32)

plt.figure(figsize=(12, 5))

# Accuracy Plot
plt.subplot(1, 2, 1)
plt.plot(history.history['accuracy'], label='Train Accuracy')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
plt.title('Model Accuracy')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.legend()

# Loss Plot
plt.subplot(1, 2, 2)
plt.plot(history.history['loss'], label='Train Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.title('Model Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()

plt.show()

# Get final training and validation accuracy
train_accuracy = history.history['accuracy'][-1]
val_accuracy = history.history['val_accuracy'][-1]

print(f"Final Training Accuracy: {train_accuracy * 100:.2f}%")
print(f"Final Validation Accuracy: {val_accuracy * 100:.2f}%")

from sklearn.preprocessing import LabelEncoder

# Initialize label encoder
label_encoder = LabelEncoder()

# Fit and transform labels
y_train = label_encoder.fit_transform(y_train)
y_test = label_encoder.transform(y_test)  # Changed y_val to y_test

# Check unique values to ensure encoding worked
print("Unique labels after encoding:", label_encoder.classes_)

print("X_train type:", type(X_train))
print("y_train type:", type(y_train))

print(X_train.dtype)

history = model.fit(
    X_train, y_train,
    epochs=50,
    validation_data=(X_test, y_test),  # Changed X_val, y_val to X_test, y_test
    # class_weight=class_weights  # If you have defined class_weights, you can uncomment this line
)

# Get final training and validation accuracy
train_accuracy = history.history['accuracy'][-1]
val_accuracy = history.history['val_accuracy'][-1]

print(f"Final Training Accuracy: {train_accuracy * 100:.2f}%")
print(f"Final Validation Accuracy: {val_accuracy * 100:.2f}%")

model.summary()

plt.figure(figsize=(12, 5))

# Accuracy Plot
plt.subplot(1, 2, 1)
plt.plot(history.history['accuracy'], label='Train Accuracy')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
plt.title('Model Accuracy')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.legend()

# Loss Plot
plt.subplot(1, 2, 2)
plt.plot(history.history['loss'], label='Train Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.title('Model Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()

plt.show()

"""# **Confusion matrix**"""

import numpy as np
import matplotlib.pyplot as plt
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay

# Generate predictions
y_true = []
y_pred = []

for images, labels in val_ds:
    predictions = model.predict(images)
    y_true.extend(labels.numpy())
    y_pred.extend(np.argmax(predictions, axis=1))

# Compute confusion matrix
cm = confusion_matrix(y_true, y_pred)
cmd = ConfusionMatrixDisplay(cm)
cmd.plot(cmap='Blues')
plt.show()

"""# Testing"""

import numpy as np
import matplotlib.pyplot as plt
from tensorflow.keras.preprocessing import image
import tensorflow as tf

# Assuming class labels are known
class_labels = ["Advance Block", "Dragonfly Doji", "Evening Doji Star", "Evening Star", "Gravestone Doji", "Hammer", "Hanging man", "Hikkake pattern",
                "Marubozu", "Morning Doji Star", "Morning Star", "Spinning top", "Three inside up-down", "Three line strike", "Three outside up-down", "Upside-Downside gap three methods"]

# Function to predict a single image
def predict_image(img_path, model):
    # Resize to match model input shape (128, 128)
    img = image.load_img(img_path, target_size=(128, 128))
    img_array = image.img_to_array(img)
    img_array = np.expand_dims(img_array, axis=0)  # Add batch dimension
    prediction = model.predict(img_array)
    predicted_class = np.argmax(prediction)
    return predicted_class, class_labels[predicted_class]

# Example usage
image_path = "/content/candlestick_data_test/Gravestone Doji/100_png_jpg.rf.23dba59485bbb3e3d49f2235dbfd9ed1.jpg"  # Replace with actual image path
predicted_class, predicted_label = predict_image(image_path, model)

# Display the image and predicted label
img = image.load_img(image_path)
plt.imshow(img)
plt.axis("off")
plt.title(f"Predicted: {predicted_label}")
plt.show()

print(f"Predicted class: {predicted_class}, Label: {predicted_label}")

"""# **Testing of image outside the dataset**

"""

import numpy as np
import matplotlib.pyplot as plt
from tensorflow.keras.preprocessing import image
import tensorflow as tf

# Assuming class labels are known
class_labels = ["Advance Block", "Dragonfly Doji", "Evening Doji Star", "Evening Star", "Gravestone Doji", "Hammer", "Hanging man", "Hikkake pattern",
                "Marubozu", "Morning Doji Star", "Morning Star", "Spinning top", "Three inside up-down", "Three line strike", "Three outside up-down", "Upside-Downside gap three methods"]

# Function to predict a single image
def predict_image(img_path, model):
    # Resize to match model input shape (128, 128)
    img = image.load_img(img_path, target_size=(128, 128))
    img_array = image.img_to_array(img)
    img_array = np.expand_dims(img_array, axis=0)  # Add batch dimension
    prediction = model.predict(img_array)
    predicted_class = np.argmax(prediction)
    return predicted_class, class_labels[predicted_class]

# Example usage
image_path = "/content/candlestick-main_0.jpg"  # Replace with actual image path
predicted_class, predicted_label = predict_image(image_path, model)

# Display the image and predicted label
img = image.load_img(image_path)
plt.imshow(img)
plt.axis("off")
plt.title(f"Predicted: {predicted_label}")
plt.show()

print(f"Predicted class: {predicted_class}, Label: {predicted_label}")

import numpy as np
import matplotlib.pyplot as plt
from tensorflow.keras.preprocessing import image
import tensorflow as tf

# Assuming class labels are known
class_labels = ["Advance Block", "Dragonfly Doji", "Evening Doji Star", "Evening Star", "Gravestone Doji", "Hammer", "Hanging man", "Hikkake pattern",
                "Marubozu", "Morning Doji Star", "Morning Star", "Spinning top", "Three inside up-down", "Three line strike", "Three outside up-down", "Upside-Downside gap three methods"]

# Function to predict a single image
def predict_image(img_path, model):
    # Resize to match model input shape (128, 128)
    img = image.load_img(img_path, target_size=(128, 128))
    img_array = image.img_to_array(img)
    img_array = np.expand_dims(img_array, axis=0)  # Add batch dimension
    prediction = model.predict(img_array)
    predicted_class = np.argmax(prediction)
    return predicted_class, class_labels[predicted_class]

# Example usage
image_path = "/content/images.png"  # Replace with actual image path
predicted_class, predicted_label = predict_image(image_path, model)

# Display the image and predicted label
img = image.load_img(image_path)
plt.imshow(img)
plt.axis("off")
plt.title(f"Predicted: {predicted_label}")
plt.show()

print(f"Predicted class: {predicted_class}, Label: {predicted_label}")